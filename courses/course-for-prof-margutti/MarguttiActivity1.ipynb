{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55de707-e705-4e95-aa56-e2a0e34f7325",
   "metadata": {},
   "source": [
    "# X-ray Data Analysis of point sources\n",
    "\n",
    "<!--<div class=\"alert alert-block alert-info\">\n",
    "</div>-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c2460-d71c-42da-9ca8-c1f8cf016894",
   "metadata": {},
   "source": [
    "Today we will perform some basic analysis on an X-ray dataset of GW170817. The goal is to understand how the raw data from a telescope must be processed to extract flux densities, which can then be used for modeling. This observation was taken with the Chandra X-ray Observatory on 2017 December 3. The data were independently published by several teams, including Margutti et al. (2018) and Ruan et al. (2018). As we will see in the extension activity, X-ray observations of GW170817 and other multi-messenger sources probe the fastest-moving ejecta from the merger. In the case of GW170817, these X-ray data helped prove that GW170817 launched a short GRB-like relativistic jet, viewed off-axis. For additional background, see Margutti & Chornock (2021) for an overview of the wide variety of science enabled by electromagnetic observations of GW170817.\n",
    "\n",
    "__Goals:__ Understand the very basics of data formats in X-ray Astronomy; get familiar with event files; understand the difference between an event and a photon; learn to filter events in time, space and energy; source detection; source counts and count-rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6819e85-2d3a-418c-8de1-ec8931adec7b",
   "metadata": {},
   "source": [
    "## 1) Getting started\n",
    "\n",
    "In this tutorial, we will use CIAO (Chandra's custom data reduction software) and ds9. ds9 is a very useful tool for interacting with astronomical images (particularly those in FITS format), and we recommend that you download it for your personal use if you expect to do data analysis in the future. If ds9 is not compatible with your operating system, you can access an online version here: https://js9.si.edu/. For this tutorial, we will use js9 integrated with this notebook. Note that some of the js9 menu options are different from the standalone application; please ask the TA for help if anything is unclear.\n",
    "\n",
    "All public Chandra data can be accessed online via the data archive browser: http://cda.harvard.edu/chaser/. Each Chandra observation is associated to an ID; you can search for data by this ID number, or by the target name, coordinates, observation date, etc. In this case, we are using the observation with ID= 20860. To expedite things, we have already downloaded the dataset that we will use in this tutorial.\n",
    "\n",
    "The data for this activity is contained in the file package_7697_220112160139.tar. In the directory where you would like to work, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094b215-7a9a-425f-be43-f176706db1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -xvf package_7697_220112160139.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f24d5-1cfd-4222-98de-0ce285ff1edc",
   "metadata": {},
   "source": [
    "You should now see a new directory with the observation ID for the downloaded dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b4f8a-a137-4ec3-abad-460cc89c8eb3",
   "metadata": {},
   "source": [
    "## 2) Structure of Chandra ACIS-S data\n",
    "We will work with Chandra ACIS-S data. Chandra has different instruments onboard. We will use ACIS-S that has the best performance when it comes to detect and characterize faint sources (we will see that the gravitational wave source is one of them).\n",
    "\n",
    "Go inside the /20860/ directory and list the items there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e731d2e-abc5-440c-b6fb-9920574c1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd 20860\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d4a668-0106-489f-b3d1-e5740d8da608",
   "metadata": {},
   "source": [
    "Go into the /primary/ folder and list the content: it contains the results from a dataset that has been already re-processed. The automatic reprocessing is good for the majority of cases (however for publication level products it is always good practice to re-process the data). For your /20860/ data the automatic processing is good enough and we will not reprocess the data ourselves. Most of the files that we need are there already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7faf5-a96e-4c2e-bb6c-99d544f81ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls 20860/primary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e4b9e-dff9-4515-8a5f-07de300c8f68",
   "metadata": {},
   "source": [
    "Most of the files in the directory are fits files (that we will use for our analysis) but we also have .jpg files that offer a very quick view of the results of the observation -but they are not useful for almost anything else-\n",
    "\n",
    "Now go into the /secondary/ folder and list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023bfa72-f26f-4bf7-82e3-9c9d69b62330",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls 20860/secondary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b974edc5-f838-48b1-8d73-68e465680c67",
   "metadata": {},
   "source": [
    "This folder contains a rich set of information about the specifics of the instrument at the time of data acquisition which are necessary to process the data correctly. You can think about /primary/ and /secondary/ as already re-processed and cleaned files (primary) vs. original data products and instrumental info (secondary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02479f38-4feb-4930-b9cd-016c756f43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVELY: open ds9 in on your laptop or in the VNC session, load the files there (please refer to instructions in https://renkulab.io/gitlab/saasfee2022/course-materials/) load the files there).\n",
    "# NOTE: if you are using ds9, or downloading regions from js9 to your latop, do not forget to upload them back to the jupyterlab notebook (see an icon on top left)\n",
    "\n",
    "import jpjs9\n",
    "J = jpjs9.JS9(id='main')\n",
    "J.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48add4d-cea5-45f6-a8b1-fff2c82435c3",
   "metadata": {},
   "source": [
    "Commands below will open in js9 the two files:  /primary/acisf20860_000N002_evt2.fits.gz and /secondary/acisf20860_000N002_evt1.fits.gz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc463d1d-0b99-492d-94b5-c495b6c8a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "J.Load('20860/primary/acisf20860N002_evt2.fits.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fe1ce-5d94-4a9d-8559-b0710ef94462",
   "metadata": {},
   "outputs": [],
   "source": [
    "J.Load('20860/secondary/acisf20860_000N002_evt1.fits.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c138ca60-af07-4f84-9676-8b8512beeb89",
   "metadata": {},
   "source": [
    "Align the two frames by going to View --> Sync Images and check the boxes for alignment, zoom, scale. (If you are using the desktop version of ds9: go into the menu Frame --> Match --> Frame --> WCS.) Blink the two frames. Remember to use log scale in both frames and adjust the contrast. What do you notice? This simple exercise is meant to make you appreciate the “beauty” of data re-processing and cleaning. Show the result to your instructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e028c6f-80a8-47bf-9a69-cb868b5cd16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: if you are using renku and the network is a bit slow, the previous command might take long and time-out.\n",
    "# In this case, try to bin the image before loading in js9\n",
    "\n",
    "#!dmcopy \"20860/secondary/acisf20860_000N002_evt1.fits.gz[bin x=1:8192:4,y=1:8192:4]\" 20860/secondary/acisf20860_000N002_evt1_binned.fits clobber=yes\n",
    "\n",
    "# using \"parentFile\" option will ensure that js9 refers operations to the original file\n",
    "#J.Load(\"20860/secondary/acisf20860_000N002_evt1_binned.fits\", {'parentFile': \"20860/secondary/acisf20860_000N002_evt1.fits.gz\"});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb67369-524b-4bf7-bec5-99f2bd9466c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, we are going to use astropy to further explore the structure and contents of this fits file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabcc274-44c4-49e4-bcaf-47a19350626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "evt2 = fits.open('20860/primary/acisf20860N002_evt2.fits.gz')\n",
    "evt2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37134d-41bf-4019-bf07-1e229979f4fe",
   "metadata": {},
   "source": [
    "js9/ds9 visualizes the image, astropy.io.fits shows the “bones” of the structure of the fits file. But it is the very same file viewed in two different ways.\n",
    "\n",
    "From the header of the first extension, named EVENTS, find out what is the exposure time of this observation. What do you find? A few lines below, you can see that there is a “dead-time” correction. What is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cddf5b-1cd1-4676-868a-d89d13f1ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evt2[1].header # display full header for the first extension (in this case 'EVENTS')\n",
    "#evt2['EVENTS'].header['EXPOSURE'] # you can also display a specific value stored in the header (in this case the exposure length in seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ebc60-1441-4dd1-863b-b4bc78326a88",
   "metadata": {},
   "source": [
    "Now we will look at the data contained in the EVENTS extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc38dce-a8e0-4e32-a963-e2b74427502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evt2[1].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a625bb5-23a7-44df-9b62-928c4efb2077",
   "metadata": {},
   "source": [
    "Each line in the table represents an “event”. This list of events has been already “cleaned” -the comparison of the evt1 to the evt2 file should have clarified what this means- and you can think about each line in the table as a count associated to some photon arriving at the detector.\n",
    "\n",
    "IMPORTANT: in X-ray Astronomy we use photon counting detectors, so we can really count the number of photons that arrived to the detector. For each photon (or things thought to be a photon), we record different info, including: the time of arrival, the location in the detector where the event arrived and the “grade”. In the table above you will find a column that contains the grade information for each event that passed the re-processing cut, and it it thus very likely associated with photons arriving at the detector.\n",
    "\n",
    "An __event__ = anything that creates a displacement of charge in the CCD (i.e. in your detector).\n",
    "\n",
    "The __grade__ is a number assigned to every event based on which pixels in its 3x3 island are above their threshold value. The initial grade is assigned by on-board processing, which first finds local maxima, then analyzes the values of the surrounding 3x3 neighboring pixels. Based on this pattern, the event is\n",
    "assigned a grade. For example, a single-pixel event has a grade of 0. There are grades that are typical of photons (Good!) and grades which are created when something else happens (bad!), like particles etc. These events will be discarded in the processing (i.e. will not pass the quality cut during the processing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e2177c-5766-4b39-b017-7548930ab0e1",
   "metadata": {},
   "source": [
    "<img src=\"fig1.png\" class=\"bg-primary\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1828d28-a8d0-4ad7-9816-1be1730df133",
   "metadata": {},
   "source": [
    "__Figure 1:__ Chandra flight grades. Do not pay attention to the color (which just describes the mapping of Chandra grades into ASCA grades, not important for you)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877e121-8132-4d0d-af46-4db48253ff7e",
   "metadata": {},
   "source": [
    "## 4) More on evt files\n",
    "\n",
    "Go back to the js9 view of the evt2 file and zoom out (or bin out if you are using ds9). This way you will be able to appreciate the structure of the CCDs that we used. You should see something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f7a08-faf5-4402-86dd-7d308cb12343",
   "metadata": {},
   "source": [
    "<img src=\"fig2.png\" class=\"bg-primary\" width=\"300px\">\n",
    "\n",
    "__Figure 2:__ binned-out view of the evt2 file.\n",
    "\n",
    "<img src=\"fig3.png\" class=\"bg-primary\" width=\"800px\">\n",
    "\n",
    "__Figure 3:__ ACIS focal plane.\n",
    "\n",
    "Figure 3 above will help you understanding what you are looking at. We are using S2 and S3 on ACIS-S and I2 and I3 from ACIS-I. From this simple exercise you can clearly appreciate the different levels of background of the different chips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8377731-9bdb-4778-8ab6-8191b872f745",
   "metadata": {},
   "source": [
    "## 5) Filtering event files in energy and in space.\n",
    "\n",
    "Using ds9 we can filter the events into a particular energy range using “Bin” (for js9, the binning functionality is under the View menu). However, instead we will do something a little more refined. The goal is to create a new evt file that is filtered in energy and in a given region.\n",
    "\n",
    "We will use the CIAO task dmcopy. To find out more about the syntax, you can use the online help:\n",
    "http://cxc.harvard.edu/ciao/ahelp/dmcopy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbde20e-b095-497a-9e3f-cc25a320757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd 20860/primary\n",
    "dmcopy \"acisf20860N002_evt2.fits.gz[ccd_id=7][energy=500:8000][bin x=3848:4360:1.0,y=3860:4372:1.0]\" evt_500_8000_img.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065efc4-4058-410d-ad33-f5f7688fd807",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "• [ccd_id=7] → we are telling CIAO that the x an y coordinates are on the CCD with id=7. Go back to Fig. 3 and see if it makes sense. Our source of interest is in S3.\n",
    "\n",
    "• [energy=500:8000] this means: filter in energy between 0.5 keV and 8 keV, which is the range where Chandra is better calibrated. \n",
    "\n",
    "• [bin x=3848:4360:1.0,y=3860:4372:1.0] this means: filter out between those xmin and xmax, ymin and ymax. In this way we are effectively reducing the size of the evt file that we will use for the following analysis, so that any operation that follows will be appreciably faster. However, we need to make sure that the the size of the final evt file is not too small around the source, or we will not have enough statistics to understand the properties of the background around the source, and hence do a reliable source detection.\n",
    "\n",
    "• evt_500_8000_img.fits: this is the name of the output file. It is good practice to save it with a name that reflects the nature of its content.\n",
    "Open evt_500_8000_img.fits with js9 and visualize the content (always log scale with X-rays!). Check the size of the new file and that the file has been filtered in energy (compare the same region of the original evt file in js9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0065766-d692-43f5-909c-f7f297e4945d",
   "metadata": {},
   "source": [
    "Check the structure of the new evt file with astropy.io.fits. How many extensions do you have? Do you notice differences with respect to the original evt file? This is because this fits file is an image (this is why I put an .img extension), i.e. we have lost the “table” structure, which means that we lost the info about the details of the arrival time of each photon. We lost the “time” coordinate and merged everything into an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab107997-21ec-4503-9106-387934e3a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_img = fits.open('20860/primary/evt_500_8000_img.fits')\n",
    "evt_img.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e6e2f-a197-4ecf-9b3f-646da12b0571",
   "metadata": {},
   "source": [
    "As a final step we will need to compute the PSF (Point Spread Function) at each position in our image. We will use the task: mkpsfmap. As always you can find out more about the task going online on the CIAO help page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347d292-567e-4eae-81eb-8394111202d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd 20860/primary\n",
    "mkpsfmap evt_500_8000_img.fits outfile=evt_500_8000_psfmap.fits energy=1.4967 ecf=0.90 clobber=yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e3017d-5143-4819-9862-9beeca26828f",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "• mkpsfmap expects as input a fits file, in this case evt_500_8000_img.fits.\n",
    "\n",
    "• The output file is also a fits file. I gave it the name evt_500_8000_psfmap.fits, so that it is easy to\n",
    "remember which image is the PSF map for.\n",
    "\n",
    "• Energy=1.4967 (keV) specifies the energy at which to compute the PSF. This is important because the PSF varies as a function of energy, so we need to specify a “typical” energy for computing the PSF. The best choice will depend on the nature of the source we are interested in. From experience I know that an energy ~1.5 keV is fine for the PSF map for the majority of cases.\n",
    "\n",
    "• Ecf= encircled energy fraction. Here we are specifying that we want the output number to be the radius, (in arcsec!) that contains the 90% of energy.\n",
    "\n",
    "Now open the newly created fits file evt_500_8000_psfmap.fits with js9. You should see something like in Figure 4 below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf5780b-3583-4bab-a3e9-32450c80d983",
   "metadata": {},
   "source": [
    "<img src=\"fig4.png\" class=\"bg-primary\" width=\"300px\">\n",
    "\n",
    "__Figure 4:__ PSF map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a58ca-e803-4e30-bef7-9b6caa1d1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we make a new view of JS9, for viewing the PSF\n",
    "J_psf = jpjs9.JS9('psf')\n",
    "J_psf.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aba451-03df-456b-8ca9-98d10e12ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_psf.Load(\"20860/primary/evt_500_8000_psfmap.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d53ab7-c8d9-442f-b800-1e3d24ebd6d7",
   "metadata": {},
   "source": [
    "If you go with your mouse over the map you will see that the values vary from ~0.9'' in the central black region to ~1.7'' in the outer regions. What you are looking at is the effect of deterioration of the PSF as we go further away from the on-axis condition . At the center an angular region as small as 0.9'' contains 90% of energy, while going further away the 90% ECF becomes significantly larger.\n",
    "\n",
    "Note: this angular resolution is AMAZING for X-ray astronomy. No other satellite can do better. Other satellites like Swift-XRT or XMM have much larger PSFs, of several arcsec (XRT has an 18 arcsec PSF)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24321a98-4415-41fd-91b9-79266c8bae28",
   "metadata": {},
   "source": [
    "## Counts and count-rates from a region (for our source, and the background).\n",
    "We will create two regions, one for our source of interest and one that we will use to estimate the background (i.e. the number of spurious counts).\n",
    "Our source of interest is GW170817, which, from optical observations we know has coordinates: \n",
    "\n",
    "RA= 13:09:48.08, \n",
    "dec= -23:22:53.3\n",
    "\n",
    "In js9, create a region of 3 arcsec around GW170817 and name it GW170817_3arcsec_optical.reg. (Go to Regions --> Circle, double click on the circle that appears in the center of the image, enter the desired coordinates and radius, and click Apply. Alternately, in the desktop ds9, go to Edit --> Region, click on the image so a green circle appears, double click on the circle, enter the desired coordinates and radius, and click Apply.) Save a version in fk5 coordinates (GW170817_3arcsec_optical.reg) and a version in physical coordinates (GW170817_3arcsec_optical_physical.reg) by editing the file name and clicking Save at the bottom of the same Edit region dialog box. When saving, under Options make sure that Save comments is checked and Save JSON object and Save dcoord regions are unchecked. (In ds9: go to Regions --> Save.) Note that this saves the .reg file on your local machine; you can easily upload this into your renku session by clicking on the upload button. \n",
    "\n",
    "__IMPORTANT:__ When you have uploaded the .reg files, double click on GW170817_3arcsec_optical_physical.reg to open it in your renku session. The first line of the .reg file specifies the Region file format as JS9 version 1.0. You must manually change this to Region file format: DS9 version 4.1 and save it before proceeding with the dmlist step below, otherwise CIAO will not know how to interpret the file correctly. \n",
    "\n",
    "Now create a circular background region. Important specs for the background region:\n",
    "\n",
    "• Must be far away from any source that you can identify with your eyes in the js9 image when\n",
    "the scale is in log units.\n",
    "\n",
    "• Must be far away from chip gaps.\n",
    "\n",
    "• Must be reasonably close to the source of interest, and preferentially in the centre of the chip.\n",
    "\n",
    "• Must be significantly larger than the source region, to protect ourselves against statistical\n",
    "fluctuations. Select a radius of ~35 arcsec or more. Do you understand what this means?\n",
    "\n",
    "As before save a version of the background region in fk5 coordinates (bk.reg) and one in physical coordinates (bk_physical.reg). Remember to also manually edit the .reg file to set the Region file format to DS9 version 4.1. You can also load and save region files from within the notebook, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2e258-62f0-40e8-a1ec-9ddcc35b8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: you can use JS9 save region functionality to avoid passing file through the local machine. \n",
    "# If you have extra time, try to make it work (beware you'll have to select and save only necessary regions)\n",
    "#J.SaveRegionFile(\"GW170817_3arcsec_optical.reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb780c26-9422-4921-a285-67cb7914dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd 20860/primary\n",
    "cp -fv ../../*.reg . # This line may not be needed if you already uploaded or saved your file directly to /20860/primary \n", 
    "dmlist 'acisf20860N002_evt2.fits.gz[energy=500:8000][sky=region(GW170817_3arcsec_optical_physical.reg)]' counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cc930a-061a-48e9-a30d-772b71c168ea",
   "metadata": {},
   "source": [
    "The CIAO dmlist task, with the option “counts” at the end, will produce as output the number of counts that are in the evt file that you provide as input, after applying all the filters you want. Each filter is defined in a “[filter]” structure. Here we are filtering in energy with [energy=500:8000](which energy band is this??) and we will only accept the counts within the SN2014C_3arcsec_optical_physical.reg region. Another way to visualize the number of photons in a region is by double clicking on the region file, Analysis, Statistics.\n",
    "\n",
    "Now estimate your “background level” in the source region, by calculating the number of 0.5-8 keV counts that you have in the background region, and then renormalize them by the size of the source region. The goal is to be able to answer to the question: how many 0.5-8 keV counts from the background do you expect to have in the source region? Compare it to the number of photons that you effectively have in the source region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b208681e-67b8-49d1-8fe3-e5e5d928f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd 20860/primary\n",
    "dmlist 'acisf20860N002_evt2.fits.gz[energy=500:8000][sky=region(bk_physical.reg)]' counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d769f7b-ffa8-4685-b2a1-7df1de0400fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample renormalization to get expected number of background counts\n",
    "expected_counts = 655*(3/35)**2\n",
    "print(expected_counts) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b0451d-ec80-4cf7-bc9c-c68234795bfd",
   "metadata": {},
   "source": [
    "Note that this is much less than the number of counts in our actual source region -- so we have a significant detection! We can also convert to an average count rate by subtracting the number of expected background counts from the number of observed counts in our source region, and then dividing by the exposure length (do you remember how to extract this from the image header, as we did above?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85083ce2-1cbd-4c02-910b-6bb170c5e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "evt2 = fits.open('20860/primary/acisf20860N002_evt2.fits.gz')\n",
    "print((114-expected_counts)/evt2['EVENTS'].header['EXPOSURE']) # units are counts per second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c678236-1d84-4778-903c-25953c466241",
   "metadata": {},
   "source": [
    "If you have chosen a good background region, this should be consistent with the count rate reported in Margutti et al (2018). In the next section, we'll explore the image a bit more and provide some tips for improving your background region if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff148ad2-77f9-4bac-ac53-026944ce0f91",
   "metadata": {},
   "source": [
    "## 7) Source Detection with wavedetect\n",
    "\n",
    "Goal: we want to find all the point-like sources in our image. Since our input is an image filtered in the energy range 0.5-8 keV, the output will be a list of point-like sources in the 0.5-8 keV range. We will use the wavedetect task within CIAO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88713dcf-165c-499e-bb35-42c95e6b9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd 20860/primary\n",
    "wavdetect infile=\"evt_500_8000_img.fits\" outfile=\"evt_500_8000_src.fits\" scellfile=\"evt_500_8000_scell.fits\" imagefile=\"evt_500_8000_imgfile.fits\" defnbkgfile=\"evt_500_8000_nbgd.fits\" regfile=\"evt_500_8000_src.reg\" scales=\" 1.0 2.0 4.0 8.0 16.0\" clobber=y sigthresh=\"4e-06\" psffile=\"evt_500_8000_psfmap.fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c4cfe3-c6a8-4cd6-98e4-9724c6291ca8",
   "metadata": {},
   "source": [
    "There are many different algorithms that can be used to detect sources. Here we will use wavelets. For fainter sources, it is possible to implement very basic and simple Poisson statistics to get solid results in the realm of source detection in the regime of very low number statistics.\n",
    "\n",
    "IMPORTANT: A source detection is always a statement about the background/noise. In a nutshell, we say that we have detected a source IF the observed counts at a certain location in the sky are in excess with respect to what we expect from the background alone (the background can be astronomical or instrumental, it does not matter here). (We will learn more in class in the next 2 lectures). Wavelets allows you to explore such deviations with respect to the background over different pixel scales.\n",
    "\n",
    "Comments about the syntax:\n",
    "\n",
    "• infile: this is your filtered image\n",
    "\n",
    "• outfile: it is going to be a fits file that contains the list of sources found. I call it “_src”\n",
    "\n",
    "• regfile: region files with the regions associated to the detected sources. The sizes of these\n",
    "regions are optimized by the algorithm to maximize the signal-to-noise in the region.\n",
    "\n",
    "• Scales: all different pixels scales over which I want to run the tool and see if I find a source. Is it\n",
    "clear why using different scales I might be able to find sources that were not appearing obvious\n",
    "before?\n",
    "\n",
    "• clobber=yes. This is just a parameter that allow the tool to overwrite on files.\n",
    "\n",
    "• Sighthresh: this is the signal threshold to define something a detection. The number I chose is good enough not to throw away potential detections, but also ok in the sense of not having too many false positives.\n",
    "\n",
    "• Psffile: this is the psfmap that we just generated with mkpsfmap. This is a necessary input as this is the way we are telling the algorithm how a point source looks like on the detector.\n",
    "\n",
    "Open evt_500_8000_img.fits with js9 (delete the psfmap frame), log scale. Now we want to see which sources have been detected: “Region” “Load”, select: evt_500_8000_src.reg\n",
    "Now open evt_500_8000_src.reg with your favorite text editor to see the structure of the file (it is a list of regions).\n",
    "\n",
    "Is GW170817 detected in this Chandra observation? Load your GW170817_3arcsec_optical.reg region and see if you have a green region around it, which means: detected! (The answer is obvious for GW170817, but it is not always this obvious, especially if we push the instrument to the very limit of its performance, which is necessary to track the full light curve evolution of gravitational wave sources.)\n",
    "\n",
    "The file evt_500_8000_src.fits contains all the relevant information for each source. Sources appear in the file in order of detection significance, from the most significant to the least:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a455d-12c3-4747-8ae3-2c85041c8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "src_img = fits.open('20860/primary/evt_500_8000_src.fits')\n",
    "src_img.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c0ed65-56f9-4076-ba69-56372b8f3c67",
   "metadata": {},
   "source": [
    "You have two extensions. Look at the data in the SRCLIST extension. Each line of this table is a detected source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10340e-41f2-4420-91ac-83f42dcd4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_img[1].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1b58e6-8695-4b72-be5f-50124344b672",
   "metadata": {},
   "source": [
    "The table contains important information, including:\n",
    "\n",
    "• Coordinates of the sources detected (RA, dec) and their absolute uncertainties (RA_err, dec_err)\n",
    "\n",
    "• X,Y: coordinates on the detector and error bar.\n",
    "\n",
    "• NET_COUNTS: background subtracted counts and uncertainty.==> Net-counts: total counts in\n",
    "the region – background counts in the region. Since we filtered the events into the 0.5-8 keV\n",
    "energy range, these are the source counts in that energy band.\n",
    "\n",
    "• BKG_COUNTS: counts from the background in the region and error bar.\n",
    "\n",
    "• RATE columns: discard. This is not a count-rate.\n",
    "\n",
    "• EXP-TIME: 1. Discard.\n",
    "\n",
    "• SRC_SIGNIFICANCE: this is an important column. It gives you the statistical information\n",
    "about the significance of the detection in units of Gaussian sigma. We will learn more about the meaning of Gaussian sigmas in the next lectures. For now, just learn that something with >= 3 sigma detection means: pretty solid detection.\n",
    "\n",
    "• PSF-SIZE (in pixels!): at the location of the source. It tells you the angular resolution of your detector at that location on the detector.\n",
    "\n",
    "• You also have some info on the shape of the regions. In js9 you can load the evt_500_8000_img.fits file together with the region file evt_500_8000_src.reg. If you click o one of the regions, you will find information about the size and shape of the region. Note that not all the regions are circular.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f84e8-92f4-48b9-b1e3-ed3d3213565c",
   "metadata": {},
   "source": [
    "Load the GW170817_3arcsec_optical.reg into js9 (use a different color for the GW170817 region – you\n",
    "can change the color of the region double clicking on the region and changing the settings in the menu that appears).\n",
    "\n",
    "Final step: identify GW170817 in the list of sources in evt_500_8000_img.fits. Which source number is GW170817? What is the easiest way to identify GW170817 in the list?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c23afe-b617-456e-b771-d05a51877af2",
   "metadata": {},
   "source": [
    "Finally load your background region on the js9 and check if it contains any of the detected sources. If it does, it means that your initial choice of background is not an ideal one and you will need to redefine the background region and re-do your estimates above with a new background region that does NOT contain any source (and it is far away from the chip gaps). The background region needs to be source- free!!\n",
    "\n",
    "Note on “event” vs. “counts” vs. “photons”: there is a reason why until now we have been speaking of counts and not of “photons” yet. A quick recap:\n",
    "\n",
    "Event= anything that creates a displacement of charge in the CCD. By assigning a grade, we effectively filter out events that have high probability of not being photons.\n",
    "\n",
    "Count= an event that is produced by photon(s), but not necessarily one photon.\n",
    "\n",
    "What happens in CCDs that are photon counting detectors, two photons that arrive very close in time to to the same pixel (or close too), can be mistakenly interpreted as one single photon with higher energy. This effect is called pile-up. Pile-up:\n",
    "\n",
    "• Is important only when the rate of photons arriving to the detector is large (how large depends on the CCD and on the mode of operation of a CCD). For the sources that we will use and our set up, pile up is not important.\n",
    "\n",
    "• Pile-up affects different portions of the PSF of a source in a different way: since most of the photons will tend to concentrate in the core of the PSF, and fewer photons will be part of the PSF tail, pile-up more severely affects the core of the PSF [this actually gives us an easy way for correct for pile-up, see reading in the folder].\n",
    "\n",
    "• By recording 2 photons as 1 photon, pile-up leads to an underestimation of the actual photon rate by the source. This directly affects the light-curve of an object.\n",
    "\n",
    "• By recording 2 lower energy photons as 1 higher energy photon, pile-up also causes a deformation of the spectrum (a spectral hardening in this case, as it goes in the direction of more energy).\n",
    "\n",
    "__VERY IMPORTANT: in X-ray astronomy you always have to report the energy band you use to extract your results. Reporting a number of counts or count-rate or any other quantity without providing the energy range is effectively is of no scientific use!!!!__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b54845-39e6-4db8-96a1-f2da379048a0",
   "metadata": {},
   "source": [
    "The final step in the data reduction process is to convert the number of counts we received to a flux density. To do this properly, X-ray astronomers need to use information about the __spectrum__ of the X-ray emission within the given energy range. (This can either be measured directly from the data if the source has enough counts, or a specific model must be assumed, e.g. a power law.) This is beyond the scope of today's activity, although we provide instructions on how to install and use a tool called Xspec to do this on your own if you are interested. The outcome of the spectrum analysis allows us to accurately convert from the observed count rate to a flux density, which can then be used for science. For the extension activity, we will explore some of the science that can be done with the full X-ray light curve of GW170817 (in combination with radio and late-time optical data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9158b59-72c4-4b71-bf91-ccca8b9b21f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
